{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from functools import partial, reduce\n",
    "from itertools import chain, product, tee, starmap\n",
    "from pysptk.synthesis import AllPoleDF, Synthesizer\n",
    "import pysptk\n",
    "from pyloudnorm import Meter\n",
    "import pyloudnorm as pyln\n",
    "from librosa.util import frame\n",
    "\n",
    "np.random.seed(114514)\n",
    "# from diffsptk import Frame, LPC, AllPoleDigitalFilter, ExcitationGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numbers = [3, 4, 5, 6, 7, 8, 9, 11, 19, 24]\n",
    "test_male = \"p360\"\n",
    "test_female = \"p361\"\n",
    "male_numbers = test_numbers[::2]\n",
    "female_numbers = test_numbers[1::2]\n",
    "paired_subject_numbers = list(\n",
    "    chain(\n",
    "        zip([test_male] * len(male_numbers), male_numbers),\n",
    "        zip([test_female] * len(female_numbers), female_numbers),\n",
    "    )\n",
    ")\n",
    "\n",
    "sr = 24000\n",
    "target_loudness = -26.0\n",
    "root_dir = \"/home/ycy/data-disk/Datasets/VCTK-Corpus-0.92-raw/24k-mic1/\"\n",
    "out_dir = \"interspeech_listening_test/\"\n",
    "\n",
    "meter = Meter(sr)\n",
    "normaliser = lambda x: pyln.normalize.loudness(\n",
    "    x, meter.integrated_loudness(x), target_loudness\n",
    ")\n",
    "\n",
    "hop_length = sr // 100\n",
    "frame_length = 1024\n",
    "lpc_order = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get normalised ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dir = \"/home/ycy/data-disk/Datasets/VCTK-Corpus-0.92-raw/24k-mic1/\"\n",
    "\n",
    "\n",
    "test_f0s = list(\n",
    "    starmap(\n",
    "        lambda subject, num: np.loadtxt(\n",
    "            Path(gt_dir) / subject / f\"{subject}_{num:03d}_mic1.pv\"\n",
    "        )[::2],\n",
    "        paired_subject_numbers,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_audio = list(\n",
    "    starmap(\n",
    "        lambda subject, num: sf.read(Path(root_dir) / subject / f\"{subject}_{num:03d}_mic1.wav\")[0],\n",
    "        paired_subject_numbers,\n",
    "    )\n",
    ")\n",
    "normalised_audio = map(normaliser, gt_audio)\n",
    "num2out_filename = (\n",
    "    lambda method, subject, num: Path(out_dir) / f\"{method}_{subject}_{num:03d}.wav\"\n",
    ")\n",
    "\n",
    "for out_filename, audio in zip(\n",
    "    starmap(partial(num2out_filename, \"gt\"), paired_subject_numbers),\n",
    "    normalised_audio,\n",
    "):\n",
    "    assert np.max(np.abs(audio)) <= 1.0, (np.max(audio), np.min(audio), out_filename)\n",
    "    sf.write(out_filename, audio, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPTK LPC baseline (low anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer = Synthesizer(AllPoleDF(order=lpc_order), hop_length)\n",
    "window = pysptk.blackman(frame_length)\n",
    "\n",
    "def lpc_analysis(audio):\n",
    "    padded = np.pad(audio, (frame_length // 2,) * 2, mode=\"reflect\")\n",
    "    lpc = pysptk.lpc(frame(padded, frame_length=frame_length, hop_length=hop_length).T * window, lpc_order)\n",
    "    lpc[:, 0] = np.log(lpc[:, 0])\n",
    "    return lpc\n",
    "\n",
    "def lpc_synth(pitch, lpc):\n",
    "    ex = pysptk.excite(pitch, hop_length, gaussian=True)\n",
    "    return synthesizer.synthesis(ex, lpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f02pitch = lambda f0: np.where(f0 > 0, sr / np.maximum(f0, 1), 0)\n",
    "lpc_recon_normalised = starmap(\n",
    "    lambda pitch, audio: normaliser(lpc_synth(pitch, lpc_analysis(audio))),\n",
    "    zip(\n",
    "        map(f02pitch, test_f0s),\n",
    "        gt_audio,\n",
    "    ),\n",
    ")\n",
    "\n",
    "for out_filename, audio in zip(\n",
    "    starmap(partial(num2out_filename, \"pysptk\"), paired_subject_numbers),\n",
    "    lpc_recon_normalised,\n",
    "):\n",
    "    assert np.max(np.abs(audio)) <= 1.0, (np.max(audio), np.min(audio), out_filename)\n",
    "    sf.write(out_filename, audio, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"golf\", \"world\", \"nhv\"]\n",
    "recon_root_dir = \"/home/ycy/data-disk/vctk-ae-pred/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_audio = starmap(\n",
    "    lambda method, subject, num: sf.read(\n",
    "        Path(recon_root_dir) / method / subject / f\"{subject}_{num:03d}_mic1.wav\"\n",
    "    )[0],\n",
    "    starmap(\n",
    "        lambda x, _: (x, *_),\n",
    "        product(methods, paired_subject_numbers),\n",
    "    ),\n",
    ")\n",
    "normalised_recon_audio = map(normaliser, recon_audio)\n",
    "\n",
    "for out_filename, audio in zip(\n",
    "    starmap(\n",
    "        num2out_filename,\n",
    "        starmap(lambda x, _: (x, *_), product(methods, paired_subject_numbers)),\n",
    "    ),\n",
    "    normalised_recon_audio,\n",
    "):\n",
    "    assert np.max(np.abs(audio)) <= 1.0, (np.max(audio), np.min(audio), out_filename)\n",
    "    sf.write(out_filename, audio, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch212",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
